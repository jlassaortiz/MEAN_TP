---
title: "MEAN_TP / MiM 2022 - UTDT"
output: html_notebook
---

# Ejercicio 1 

## Cargamos los datos

```{r}
# PRIMER PASO! Ingresamos el directorio donde están los datos en la consola
directorio_datos <- readline("Directorio datos: ")
directorio_datos <- paste0(directorio_datos, '/ebay_data.txt')


# Cargo datos
datos <- read.csv(directorio_datos, sep = ';')

# Transformamos atributo fecha (char) a formato fecha posta
datos$date <-  as.Date(datos$date, format = '%d/%m/%Y')

# Vemos un breve resumen de los datos
summary(datos)
```

# Gráficos descriptivos

Hacemos gráficos para ver con mas detalle nuestros datos y que de esta forma nos ayuden a encontrar outliers o errores en la base 

```{r}
library(ggplot2)

ggplot(data = datos, aes(date, fill = as.factor(post))) +
   geom_histogram(alpha=0.5, position="identity", binwidth = 1)+
  labs(x = 'fechas') +
  scale_fill_discrete(name = "posteriores a 23/5/2016",labels = c('0', '1'))+
  theme_classic()

ggplot(data = datos, aes(as.factor(post), fill = as.factor(post)))+
  geom_bar(alpha = 0.5)+
  labs(x = 'posteado antes o después del 23/5/2016')+
  theme_classic() +
  theme(legend.position =  'none')

ggplot(data = datos, aes(as.factor(itemsold)))+
  geom_bar()+
  labs(x = 'venta (no se vendió / se vendió)') +
  theme_classic()

ggplot(data = datos, aes(as.factor(desktop)))+
  geom_bar()+
  labs(x = 'comprador usó versión desktop (sino mobil)')+
  theme_classic()
  
ggplot(data = datos, aes(as.factor(category)))+
  geom_bar(alpha = 0.5)+
  labs(x = 'categoría del producto')+
  theme_classic()+
  theme(legend.position =  'none')

ggplot(data = datos, aes(as.factor(condition)))+
  geom_bar()+
  labs(x = 'condición (usado o nuevo)')+
  theme_classic()
```

Estos gráficos nos informan que las variables descriptas no tienen serios desbalanceos, todas estarían igualmente representadas. El caso es distinto para los atributos que graficámos a continuación.

```{r}
ggplot(data = datos, aes(askingprice))+
  geom_histogram(binwidth = 50) +
  xlim(NA, 2000) +
  labs(x = 'precio ofrecido')+
  theme_classic()

ggplot(data = datos, aes(precipitation))+
  geom_histogram()+
  labs(x = 'días de lluvias')+
  theme_classic()

ggplot(data = datos, aes(temp))+
  geom_histogram()+
  labs(x = 'temperatura')+
  theme_classic()

ggplot(data = datos, aes(as.factor(holiday)))+
  geom_bar()+
  labs(x = 'época de vacaciones')+
  theme_classic()

ggplot(data = datos, aes(as.factor(message)))+
  geom_bar()+
  labs(x = 'Comprador envió un mensaje') +
  theme_classic()
```

Finalmente, las variables `buyerid` e `itemid` no lucen como esperamos. Resulta extraño que la cantidad de ofertas de compradores luzca escalonada, es decir que falten valores intermedios (compradores que ofertaron 700 veces por ejemplo). 

Para el id de los items resulta extraño que solo haya 5 items en toda la muestra. 

Consideramos que estos atributos de la base de datos no son correctos y que sus valores pueden deberse a un error en el armado de la misma. 


```{r}
ggplot(data = datos, aes(as.factor(itemid)))+
  geom_bar()+
  labs(x = 'id del item')+
  theme_classic()

ggplot(data = datos, aes(as.factor(buyerid)))+
  geom_bar()+
  labs(x = 'id del comprador')+
  theme_classic()
```
## Composición de las publicaciones según categoría
Vemos que las categorías están bastante distribuidas, todas las categorías tienen alrededor del 20% de las publicaciones (este es un comportamiento que resulta contra-intuitivo, ya que generalmente por ejemplo la categoría libros tiene mucho mas items que la categoría de joyería y relojes)

```{r}
table(datos$category)
prop.table(table(datos$category))
```

Vamos a hacer la misma comparación pero con el porcentaje de publicaciones que se concretaron en ventas (tomando únicamente items vendidos)

```{r}
solo_ventas = datos[(datos$itemsold == 1),]
table(solo_ventas$category[])
prop.table(table(solo_ventas$category))
```

Ya empezamos a ver diferencias, claramente por más que las publicaciones estén balanceadas, hay algunas categorías en las cuales se realizan muchas más ventas que en otras categorías. Vamos a hacer un último análisis incorporando la variable del precio para obtener las ventas en pesos:

```{r}
solo_ventas = datos[(datos$itemsold == 1),]

library(dplyr)
sales_by_cat <- solo_ventas %>% 
                        group_by(category) %>% 
                        summarise(totalSales = sum(askingprice))
sales_by_cat$percentage <- sales_by_cat$totalSales/sum(sales_by_cat$totalSales)
sales_by_cat
```
Podemos observar que si bien el mayor porcentaje de las unidades vendidas corresponde a los libros (alrededor de un 30%), si evaluamos en terminos de facturacion corresponde a un porcentaje muy bajo (3.7% aproximadamente), mientras que un 53% corresponde a la categoría de electrónica (un 12% de las publicaciones con venta concretada), y un 26% corresponde a joyería y relojes (17% de las publicaciones de venta).

# Ejercicio 2
Para cada uno de los cuatro conjuntos armo los conjuntos debidos a los parámetros y construyo los intervalos de confianza

```{r}
data_Desktop_antes = datos[(datos$desktop == 1 & datos$post == 0),]
IntervaloDesktopAntes <- binom.test(x=sum(data_Desktop_antes$itemsold), n=nrow(data_Desktop_antes), conf.level=0.95)$conf.int

data_movile_antes = datos[(datos$desktop==0 & datos$post==0),]
IntervaloMovileAntes<- binom.test(x=sum(data_movile_antes$itemsold), n=nrow(data_movile_antes), conf.level=0.95)$conf.int

data_Desktop_despues = datos[(datos$desktop == 1 & datos$post == 1),]
IntervaloDesktopDespues <- binom.test(x=sum(data_Desktop_despues$itemsold), n=nrow(data_Desktop_despues), conf.level=0.95)$conf.int

data_movile_despues = datos[(datos$desktop==0 & datos$post==1),]
IntervaloMovileDespues<- binom.test(x=sum(data_movile_despues$itemsold), n=nrow(data_movile_despues), conf.level=0.95)$conf.int
```

Ahora quiero ver los intervalos de confianza
```{r}
IntervaloDesktopAntes
IntervaloDesktopDespues
IntervaloMovileAntes
IntervaloMovileDespues

nombres <- c('Desktop Antes', 'Desktop Despues', 'Movile Antes', 'Moviles Despues')
intervalo_up <- c(IntervaloDesktopAntes[1], IntervaloDesktopDespues[1], IntervaloMovileAntes[1], IntervaloMovileDespues[1])
intervalo_down <- c(IntervaloDesktopAntes[2], IntervaloDesktopDespues[2], IntervaloMovileAntes[2], IntervaloMovileDespues[2])

intervalos <- data.frame(nombres, intervalo_up, intervalo_down)

ggplot(data = intervalos, aes(1, color = as.factor(nombres)))+
  geom_errorbar(aes(ymin = intervalo_down, ymax = intervalo_up), size = 1.5)+
  labs(color = "") +
  theme_classic() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

Al comparar los intervalos de confianza de la proporción de ventas en la versión Desktop antes y después del 23 de mayo, se puede observar que no hay solapamiento de los intervalos. Esto indica evidencia estadística significativa de que la proporción de ventas en la versión desktop cambió de manera relevante a partir del 23 de mayo.

De la misma manera, al comparar los intervalos de confianza de la proporción de ventas en la versión Movile antes y después del 23 de mayo, se observa que no hay solapamiento de intervalos, otorgando nuevamente evidencia estadística significativa del cambio notable que se dio en la proporción de ventas a partir del 23 de mayo.

También se puede observar que el update incluido en la plataforma que permite la comunicación por mensajes entre vendedores y compradores, tuvo un impacto mucho mayor en la proporción de las ventas en la versión Desktop. Se llega a esta conclusión porque si bien, ambas versiones de la plataforma tuvieron cambios significativos en su proporción de ventas, los intervalos de confianza de la versión desktop antes y después del 23 de mayo se encuentran mucho más separados que aquellos de la versión movile antes y después del 23. Esta gran distancia entre los intervalos en la versión desktop sugiere evidencia de un fuerte impacto en la proporción de ventas.



# Ejercicio 3
```{r}
#Este le toca a Vir
```








# Ejercicio 4
```{r}
#Este tambi?n le toca a Vir 
```









# Ejercicio 5

```{r}
regresion <- lm(data = datos, itemsold ~ desktop + post + desktop * post)
summary(regresion)
```

Según los estimadores de este modelo podemos decir que la probabilidad que se realice una compra para un artículo visto desde la versión desktop y posteado después del 23/5/2016 es de 

$\beta_0 + \beta_{desktop}*1 + \beta_{post}*1 + \beta_{desktop*post}*1*1 = 0.45 +  0.02 + 0.02 + 0.04 = 0.53$

La probabilidad que se realice una compra para un artículo visto desde la versión móvil y posteado después del 23/5/2016 es:
 
$\beta_0 + \beta_{desktop}*0 + \beta_{post}*1 + \beta_{desktop*post}*1*0 = 0.45 +  0+ 0.02 + 0 = 0.47$
 
La probalidad que se realice una compra para un artículo visto desde la versión móvil y posteado antes del 23/5/2016 es:
 
$\beta_0 + \beta_{desktop}*0 + \beta_{post}*0 + \beta_{desktop*post}*0*0 = 0.45 +  0 + 0 + 0 = 0.45$

La probabilidad que se realice una compra para un artículo visto desde la versión desktop y posteado antes del 23/5/2016 es:

$\beta_0 + \beta_{desktop}*1 + \beta_{post}*0 + \beta_{desktop*post}*0*1 = 0.45 +  0.02 + 0 + 0 = 0.47$


Para evaluar el efeto de la comunicación efectiva hago otro modelo a partir de este sumando la variable `messsage`

```{r}
regresion_2a <- lm(data = datos, itemsold ~ desktop + post + message + desktop*post)
summary(regresion_2a)
```

El hecho que se hayan enviado efectivamente un mensaje aumenta la probabilidad de la venta en 17 puntos porcentuales.

Notar que en este nuevo modelo, al sumar `messsage`,  la variable `desktop` pierde significancia estadística. 


# Ejercicio 6

```{r}
regresion_2b <- lm(data = datos, itemsold ~ desktop + post + message + condition  + desktop*post)
summary(regresion_2b)
```

Los resultados son muy similares. Los estimadores casi no cambian. El efecto del la condición del producto sobre la probabilidad de de venta es baja. El hecho que un producto sea nuevo disminuye la probabilidad de compra en 5 puntos porcentuales. 

Este resultado nos llama la atención y nos preguntamos si la condición no será colineal con el precio. Hacemos otro modelo agregando el precio. 

```{r}
regresion_2c <- lm(data = datos, itemsold ~ desktop + post + message + condition  + askingprice + desktop*post)
summary(regresion_2c)
```

Al agregar la variable `askingprice` los efectos marginales de las variables son muy similares a los del `modelo_2b`. Si hay colinealidad entre las variables `askingprice` y `condition`, la misma es leve.


# Ejercicio 7

```{r}
regresion_3 <- lm(data = datos, itemsold ~ desktop + post + desktop*post + temp + precipitation)
summary(regresion_3)
```


```{r}
regresion_4 <- lm(data = datos, itemsold ~ desktop + post + condition + desktop*post + temp + precipitation)
summary(regresion_4)
```

Si sobre las regresiones de los puntos (5) y (6) agregamos como variables de control las variables climáticas, las estimaciones cambian porque están correlacionadas. Pero es una correlación espuria dado que esta relación estadástica no debería existir. Ni la temperatura ni las precipitaciones deberían tener relación estadística con las variables incluidas en este modelo.



# Ejercicio 8

```{r}
GroupA<-sample(datos, 38, replace=TRUE)
GroupB<-sample(datos, 38, replace=TRUE)
```

Hacemos un re-muestreo con reemplazo a partir de la muestra original y calculamos los IC del punto (2) para ambos grupos.

```{r}
Data_Desktop_Antes_A = GroupA[(GroupA$desktop == 1 & GroupA$post == 0),]
IntervaloDesktopAntes_A <- binom.test(x=sum(Data_Desktop_Antes_A$itemsold), n=nrow(Data_Desktop_Antes_A), conf.level=0.95)$conf.int

Data_Mobile_Antes_A = GroupA[(GroupA$desktop==0 & GroupA$post==0),]
IntervaloMobileAntes_A <- binom.test(x=sum(Data_Mobile_Antes_A$itemsold), n=nrow(Data_Mobile_Antes_A), conf.level=0.95)$conf.int

Data_Desktop_Despues_A = GroupA[(GroupA$desktop == 1 & GroupA$post == 1),]
IntervaloDesktopDespues_A <- binom.test(x=sum(Data_Desktop_Despues_A$itemsold), n=nrow(Data_Desktop_Despues_A), conf.level=0.95)$conf.int

Data_Mobile_Despues_A = GroupA[(GroupA$desktop==0 & GroupA$post==1),]
IntervaloMobileDespues_A <- binom.test(x=sum(Data_Mobile_Despues_A$itemsold), n=nrow(Data_Mobile_Despues_A), conf.level=0.95)$conf.int
```

```{r}
Data_Desktop_Antes_B = GroupB[(GroupB$desktop == 1 & GroupB$post == 0),]
IntervaloDesktopAntes_B <- binom.test(x=sum(Data_Desktop_Antes_B$itemsold), n=nrow(Data_Desktop_Antes_B), conf.level=0.95)$conf.int

Data_Mobile_Antes_B = GroupB[(GroupB$desktop==0 & GroupB$post==0),]
IntervaloMobileAntes_B <- binom.test(x=sum(Data_Mobile_Antes_B$itemsold), n=nrow(Data_Mobile_Antes_B), conf.level=0.95)$conf.int

Data_Desktop_Despues_B = GroupB[(GroupB$desktop == 1 & GroupB$post == 1),]
IntervaloDesktopDespues_B <- binom.test(x=sum(Data_Desktop_Despues_B$itemsold), n=nrow(Data_Desktop_Despues_B), conf.level=0.95)$conf.int

Data_Mobile_Despues_B = GroupB[(GroupB$desktop==0 & GroupB$post==1),]
IntervaloMobileDespues_B <- binom.test(x=sum(Data_Mobile_Despues_B$itemsold), n=nrow(Data_Mobile_Despues_B), conf.level=0.95)$conf.int
```

Revisamos resultados obtenidos.

```{r}
IntervaloDesktopAntes_A
IntervaloDesktopDespues_A
IntervaloMobileAntes_A
IntervaloMobileDespues_A
```

```{r}
IntervaloDesktopAntes_B
IntervaloDesktopDespues_B
IntervaloMobileAntes_B
IntervaloMobileDespues_B
```

